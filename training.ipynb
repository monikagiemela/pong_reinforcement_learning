{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS6Fq7zwzp28",
        "outputId": "2dae4fbb-912b-4b22-8512-2ab05f17b51b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpf2eXRMWBQS",
        "outputId": "2ddeabfb-4f37-4892-e217-5dc7e2a646d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/IU/reinforcement_learning/v6/checkpoints\n"
          ]
        }
      ],
      "source": [
        "%ls /content/drive/MyDrive/IU/reinforcement_learning/v8/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UJuxnn7Oebo",
        "outputId": "375559e8-c96f-4f89-8bcc-793445251c9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rGet:2 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [4 InRelea\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected\r                                                                               \rGet:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r0% [5 InRelease 0 B/128 kB 0%] [Waiting for headers] [Waiting for headers] [Con\r0% [5 InRelease 15.6 kB/128 kB 12%] [Waiting for headers] [Waiting for headers]\r                                                                               \rGet:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,045 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 2,307 kB in 1s (1,996 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-opengl is already the newest version (3.1.5+dfsg-1).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.15).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n",
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (0.11.2)\n",
            "Requirement already satisfied: gymnasium[accept-rom-license] in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "\u001b[33mWARNING: gymnasium 1.2.0 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license]) (0.0.4)\n",
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.12/dist-packages (0.11.2)\n",
            "Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.12/dist-packages (from ale-py) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.32.4)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Device: cuda, state shape: (4, 84, 84), actions: 6\n",
            "Loading checkpoint: /content/drive/MyDrive/IU/reinforcement_learning/v8/checkpoints/checkpoint_ep4500_20250930_094734.pth\n",
            "Loading replay buffer...\n",
            "Loaded buffer with 25000 experiences\n",
            "Resumed from episode 4500, frame 10210364\n",
            "Starting training from episode 4500 with 25000 experiences in buffer...\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.04GB / 0.07GB\n",
            "Ep 4510/5000, ε=0.010, Loss=0.0009, AvgR=18.75\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4520/5000, ε=0.010, Loss=0.0009, AvgR=18.42\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4530/5000, ε=0.010, Loss=0.0007, AvgR=18.32\n",
            "RAM Usage: 24.4%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4540/5000, ε=0.010, Loss=0.0004, AvgR=18.37\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4550/5000, ε=0.010, Loss=0.0003, AvgR=18.38\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Checkpoint saved: /content/drive/MyDrive/IU/reinforcement_learning/v8/checkpoints/checkpoint_ep4550_20250930_101935.pth\n",
            "Ep 4560/5000, ε=0.010, Loss=0.0006, AvgR=18.37\n",
            "RAM Usage: 24.4%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4570/5000, ε=0.010, Loss=0.0004, AvgR=18.35\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4580/5000, ε=0.010, Loss=0.0007, AvgR=18.16\n",
            "RAM Usage: 24.4%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4590/5000, ε=0.010, Loss=0.0004, AvgR=17.99\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4600/5000, ε=0.010, Loss=0.0012, AvgR=17.86\n",
            "RAM Usage: 24.2%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Checkpoint saved: /content/drive/MyDrive/IU/reinforcement_learning/v8/checkpoints/checkpoint_ep4600_20250930_103739.pth\n",
            "Ep 4610/5000, ε=0.010, Loss=0.0006, AvgR=17.91\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4620/5000, ε=0.010, Loss=0.0031, AvgR=18.01\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4630/5000, ε=0.010, Loss=0.0005, AvgR=18.29\n",
            "RAM Usage: 24.2%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4640/5000, ε=0.010, Loss=0.0039, AvgR=18.17\n",
            "RAM Usage: 24.2%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4650/5000, ε=0.010, Loss=0.0011, AvgR=18.05\n",
            "RAM Usage: 24.2%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Checkpoint saved: /content/drive/MyDrive/IU/reinforcement_learning/v8/checkpoints/checkpoint_ep4650_20250930_105507.pth\n",
            "Ep 4660/5000, ε=0.010, Loss=0.0006, AvgR=18.09\n",
            "RAM Usage: 24.2%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4670/5000, ε=0.010, Loss=0.0002, AvgR=18.17\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4680/5000, ε=0.010, Loss=0.0014, AvgR=18.36\n",
            "RAM Usage: 24.2%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4690/5000, ε=0.010, Loss=0.0010, AvgR=18.42\n",
            "RAM Usage: 24.1%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4700/5000, ε=0.010, Loss=0.0014, AvgR=18.48\n",
            "RAM Usage: 24.2%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Checkpoint saved: /content/drive/MyDrive/IU/reinforcement_learning/v8/checkpoints/checkpoint_ep4700_20250930_111229.pth\n",
            "Ep 4710/5000, ε=0.010, Loss=0.0011, AvgR=18.43\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4720/5000, ε=0.010, Loss=0.0003, AvgR=18.43\n",
            "RAM Usage: 24.2%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4730/5000, ε=0.010, Loss=0.0008, AvgR=18.28\n",
            "RAM Usage: 24.1%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4740/5000, ε=0.010, Loss=0.0003, AvgR=18.26\n",
            "RAM Usage: 24.2%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4750/5000, ε=0.010, Loss=0.0007, AvgR=18.24\n",
            "RAM Usage: 24.1%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Checkpoint saved: /content/drive/MyDrive/IU/reinforcement_learning/v8/checkpoints/checkpoint_ep4750_20250930_112937.pth\n",
            "Ep 4760/5000, ε=0.010, Loss=0.0003, AvgR=18.21\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4770/5000, ε=0.010, Loss=0.0006, AvgR=18.12\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4780/5000, ε=0.010, Loss=0.0001, AvgR=18.12\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4790/5000, ε=0.010, Loss=0.0003, AvgR=18.26\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Ep 4800/5000, ε=0.010, Loss=0.0009, AvgR=18.34\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n",
            "Checkpoint saved: /content/drive/MyDrive/IU/reinforcement_learning/v8/checkpoints/checkpoint_ep4800_20250930_114637.pth\n",
            "Ep 4810/5000, ε=0.010, Loss=0.0002, AvgR=18.40\n",
            "RAM Usage: 24.3%\n",
            "GPU Memory: 0.05GB / 0.07GB\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y xvfb python3-opengl ffmpeg\n",
        "!pip install gymnasium[atari]\n",
        "!pip install gymnasium[accept-rom-license]\n",
        "!pip install ale-py\n",
        "!pip install torch torchvision torchaudio moviepy matplotlib\n",
        "\n",
        "import os\n",
        "os.environ['SDL_VIDEODRIVER'] = 'dummy'\n",
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium.wrappers import AtariPreprocessing\n",
        "from gymnasium.wrappers import FrameStackObservation\n",
        "import ale_py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import math\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import json\n",
        "import pickle\n",
        "import gc\n",
        "import psutil\n",
        "\n",
        "# Directories\n",
        "checkpoint_dir = Path('/content/drive/MyDrive/IU/reinforcement_learning/v8/checkpoints')\n",
        "logs_dir = Path('/content/drive/MyDrive/IU/reinforcement_learning/v8/logs')\n",
        "checkpoint_dir.mkdir(exist_ok=True)\n",
        "logs_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# --- Environment ---\n",
        "env = gym.make('ALE/Pong-v5', render_mode='rgb_array', frameskip=1)\n",
        "env = AtariPreprocessing(env, grayscale_obs=True, scale_obs=False, terminal_on_life_loss=True)\n",
        "env = FrameStackObservation(env, stack_size=4)\n",
        "\n",
        "num_state_feats = env.observation_space.shape\n",
        "num_actions = env.action_space.n\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}, state shape: {num_state_feats}, actions: {num_actions}\")\n",
        "\n",
        "# --- Dueling DQN ---\n",
        "class DuelingDQN(nn.Module):\n",
        "    \"\"\"Convolutional neural network for the Atari games.\"\"\"\n",
        "    def __init__(self, num_actions):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(4, 32, kernel_size=8, stride=4)\n",
        "        std = math.sqrt(2.0 / (4 * 84 * 84))\n",
        "        nn.init.normal_(self.conv1.weight, 0.0, std)\n",
        "        self.conv1.bias.data.fill_(0.0)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        std = math.sqrt(2.0 / (32 * 4 * 8 * 8))\n",
        "        nn.init.normal_(self.conv2.weight, 0.0, std)\n",
        "        self.conv2.bias.data.fill_(0.0)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        std = math.sqrt(2.0 / (64 * 32 * 4 * 4))\n",
        "        nn.init.normal_(self.conv3.weight, 0.0, std)\n",
        "        self.conv3.bias.data.fill_(0.0)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
        "        std = math.sqrt(2.0 / (64 * 64 * 3 * 3))\n",
        "        nn.init.normal_(self.fc1.weight, 0.0, std)\n",
        "        self.fc1.bias.data.fill_(0.0)\n",
        "\n",
        "        self.V = nn.Linear(512, 1)\n",
        "        self.A = nn.Linear(512, num_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass of the neural network with some inputs.\"\"\"\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.fc1(x.view(x.size(0), -1))) # Flatten input.\n",
        "        V = self.V(x)\n",
        "        A = self.A(x)\n",
        "        return V + (A - A.mean(dim=1, keepdim=True))\n",
        "\n",
        "# Create main and target neural networks.\n",
        "main_nn = DuelingDQN(num_actions).to(device)\n",
        "target_nn = DuelingDQN(num_actions).to(device)\n",
        "\n",
        "# Loss function and optimizer.\n",
        "optimizer = torch.optim.Adam(main_nn.parameters(), lr=1e-5)\n",
        "loss_fn = nn.SmoothL1Loss() # Huber loss\n",
        "\n",
        "# --- Epsilon-greedy ---\n",
        "def select_epsilon_greedy_action(state, epsilon):\n",
        "    \"\"\"Take random action with probability epsilon, else take best action.\"\"\"\n",
        "    if np.random.rand() < epsilon:\n",
        "        return env.action_space.sample() # Random action.\n",
        "    with torch.no_grad():\n",
        "        qs = main_nn(state).cpu().numpy()\n",
        "    return int(np.argmax(qs))\n",
        "\n",
        "# --- Replay Buffer ---\n",
        "class UniformBuffer:\n",
        "    \"\"\"Experience replay buffer that samples uniformly.\"\"\"\n",
        "    def __init__(self, size, device):\n",
        "        self._size = size\n",
        "        self.buffer = []\n",
        "        self.device = device\n",
        "        self._next_idx = 0\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        if state.dtype != np.uint8:\n",
        "            state = (state * 255).astype(np.uint8) if state.max() <= 1.0 else state.astype(np.uint8)\n",
        "        if next_state.dtype != np.uint8:\n",
        "            next_state = (next_state * 255).astype(np.uint8) if next_state.max() <= 1.0 else next_state.astype(np.uint8)\n",
        "\n",
        "        # Make sure we're not storing unnecessary copies\n",
        "        state_compact = np.ascontiguousarray(state)\n",
        "        next_state_compact = np.ascontiguousarray(next_state)\n",
        "\n",
        "        if self._next_idx >= len(self.buffer):\n",
        "            self.buffer.append((state_compact, action, reward, next_state_compact, done))\n",
        "        else:\n",
        "            self.buffer[self._next_idx] = (state_compact, action, reward, next_state_compact, done)\n",
        "        self._next_idx = (self._next_idx + 1) % self._size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def sample(self, num_samples):\n",
        "        indices = np.random.choice(len(self.buffer), num_samples, replace=False)\n",
        "\n",
        "        # Pre-allocate arrays for better memory efficiency\n",
        "        states = np.empty((num_samples, 4, 84, 84), dtype=np.float32)\n",
        "        next_states = np.empty((num_samples, 4, 84, 84), dtype=np.float32)\n",
        "        actions = np.empty(num_samples, dtype=np.int64)\n",
        "        rewards = np.empty(num_samples, dtype=np.float32)\n",
        "        dones = np.empty(num_samples, dtype=np.float32)\n",
        "\n",
        "        for idx, i in enumerate(indices):\n",
        "            s, a, r, ns, d = self.buffer[i]\n",
        "            states[idx] = s.astype(np.float32) / 255.0\n",
        "            next_states[idx] = ns.astype(np.float32) / 255.0\n",
        "            actions[idx] = a\n",
        "            rewards[idx] = r\n",
        "            dones[idx] = d\n",
        "\n",
        "        # Convert to tensors\n",
        "        states_tensor = torch.from_numpy(states).to(self.device)\n",
        "        next_states_tensor = torch.from_numpy(next_states).to(self.device)\n",
        "        actions_tensor = torch.from_numpy(actions).to(self.device)\n",
        "        rewards_tensor = torch.from_numpy(rewards).to(self.device)\n",
        "        dones_tensor = torch.from_numpy(dones).to(self.device)\n",
        "\n",
        "        return states_tensor, actions_tensor, rewards_tensor, next_states_tensor, dones_tensor\n",
        "\n",
        "# --- Training step with Double DQN ---\n",
        "def train_step(states, actions, rewards, next_states, dones):\n",
        "    next_qs_argmax = main_nn(next_states).argmax(dim=-1, keepdim=True)\n",
        "    masked_next_qs = target_nn(next_states).gather(1, next_qs_argmax).squeeze()\n",
        "    target = rewards + (1 - dones) * discount * masked_next_qs\n",
        "    masked_qs = main_nn(states).gather(1, actions.unsqueeze(-1)).squeeze()\n",
        "    loss = loss_fn(masked_qs, target.detach())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss\n",
        "\n",
        "# Hyperparameters\n",
        "num_episodes = 5000\n",
        "epsilon = 1.0\n",
        "batch_size = 32\n",
        "discount = 0.99\n",
        "buffer_size = 25000\n",
        "save_interval = 50\n",
        "log_interval = 10\n",
        "\n",
        "buffer = UniformBuffer(buffer_size, device)\n",
        "\n",
        "# Training state\n",
        "training_state = {'episode':0, 'epsilon':epsilon, 'cur_frame':0, 'last_100_ep_rewards':[], 'training_logs':{'episodes':[], 'rewards':[], 'avg_rewards':[], 'losses':[], 'epsilon_values':[], 'frames':[]}}\n",
        "\n",
        "# Load from checkpoint if available\n",
        "def load_latest_checkpoint():\n",
        "    checkpoint_files = list(checkpoint_dir.glob(\"checkpoint_ep*.pth\"))\n",
        "    if not checkpoint_files:\n",
        "        print(\"No checkpoints found. Starting from scratch.\")\n",
        "        return False\n",
        "\n",
        "    # Find the latest checkpoint by episode number\n",
        "    latest_checkpoint = max(checkpoint_files, key=lambda x: int(x.stem.split('_')[1][2:]))\n",
        "    print(f\"Loading checkpoint: {latest_checkpoint}\")\n",
        "\n",
        "    try:\n",
        "        with torch.serialization.safe_globals([np.core.multiarray.scalar]):\n",
        "            checkpoint = torch.load(latest_checkpoint, map_location=device, weights_only=False)\n",
        "\n",
        "        # Load model states\n",
        "        main_nn.load_state_dict(checkpoint['main_nn_state_dict'])\n",
        "        target_nn.load_state_dict(checkpoint['target_nn_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "        # Load training state\n",
        "        global training_state\n",
        "        training_state = checkpoint['training_state']\n",
        "        checkpoint_filename = latest_checkpoint.name\n",
        "        buffer_filename = f\"buffer_{checkpoint_filename.replace('.pth', '.pkl')}\"\n",
        "        buffer_filepath = checkpoint_dir / buffer_filename\n",
        "\n",
        "        if buffer_filepath.exists():\n",
        "            print(\"Loading replay buffer...\")\n",
        "            with open(buffer_filepath, 'rb') as f:\n",
        "                buffer.buffer = pickle.load(f)\n",
        "                buffer._next_idx = len(buffer.buffer) % buffer._size\n",
        "            print(f\"Loaded buffer with {len(buffer.buffer)} experiences\")\n",
        "        else:\n",
        "            print(f\"No buffer file found at {buffer_filepath}, starting with empty buffer\")\n",
        "\n",
        "        print(f\"Resumed from episode {checkpoint['episode']}, frame {training_state['cur_frame']}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading checkpoint: {e}\")\n",
        "        print(\"Starting from scratch.\")\n",
        "        return False\n",
        "\n",
        "# Load checkpoint if available\n",
        "checkpoint_loaded = load_latest_checkpoint()\n",
        "\n",
        "# --- Checkpoints (with buffer size limit) ---\n",
        "def save_checkpoint(episode, main_nn, target_nn, optimizer, buffer, training_state):\n",
        "    filename = f\"checkpoint_ep{episode}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth\"\n",
        "    filepath = checkpoint_dir/filename\n",
        "    checkpoint = {\n",
        "        'episode': episode,\n",
        "        'main_nn_state_dict': main_nn.state_dict(),\n",
        "        'target_nn_state_dict': target_nn.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'training_state': training_state\n",
        "    }\n",
        "    # Limit buffer saving\n",
        "    buffer_filepath = checkpoint_dir/f\"buffer_{filename.replace('.pth','.pkl')}\"\n",
        "    with open(buffer_filepath,'wb') as f:\n",
        "        pickle.dump(buffer.buffer[:len(buffer)], f)  # Only save used portion\n",
        "\n",
        "    torch.save(checkpoint, filepath)\n",
        "    print(f\"Checkpoint saved: {filepath}\")\n",
        "    return filepath\n",
        "\n",
        "# --- Memory monitoring function ---\n",
        "def print_memory_usage():\n",
        "    print(f\"RAM Usage: {psutil.virtual_memory().percent:.1f}%\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU Memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB / {torch.cuda.max_memory_allocated()/1024**3:.2f}GB\")\n",
        "\n",
        "last_100_ep_rewards = training_state['last_100_ep_rewards']\n",
        "cur_frame = training_state['cur_frame']\n",
        "epsilon = training_state['epsilon']\n",
        "start_episode = training_state['episode']\n",
        "loss_val = torch.tensor(0.0)\n",
        "\n",
        "print(f\"Starting training from episode {start_episode} with {len(buffer)} experiences in buffer...\")\n",
        "print_memory_usage()\n",
        "\n",
        "# Start training. Play game once and then train with a batch.\n",
        "for episode in range(start_episode + 1, num_episodes + 1):  # Start from next episode\n",
        "    state, _ = env.reset()\n",
        "    ep_reward, done = 0, False\n",
        "\n",
        "    # Force garbage collection at episode start\n",
        "    if episode % 25 == 0:\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    while not done:\n",
        "        # Convert state to tensor for action selection (minimize memory usage)\n",
        "        state_tensor = torch.from_numpy(state.astype(np.float32) / 255.0).unsqueeze(0).to(device)\n",
        "        action = select_epsilon_greedy_action(state_tensor, epsilon)\n",
        "\n",
        "        # Clear the temporary tensor immediately\n",
        "        del state_tensor\n",
        "\n",
        "        next_state, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        ep_reward += reward\n",
        "        reward = np.sign(reward)\n",
        "\n",
        "        # Store in buffer\n",
        "        buffer.add(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        cur_frame += 1\n",
        "        if epsilon > 0.01:\n",
        "            epsilon -= 1.1e-6\n",
        "\n",
        "        if len(buffer) >= batch_size:\n",
        "            states, actions, rewards, next_states, dones = buffer.sample(batch_size)\n",
        "            loss_val = train_step(states, actions, rewards, next_states, dones)\n",
        "\n",
        "            # Clear tensors after training step\n",
        "            del states, actions, rewards, next_states, dones\n",
        "\n",
        "        # Copy main_nn weights to target_nn.\n",
        "        if cur_frame % 10000 == 0:\n",
        "            target_nn.load_state_dict(main_nn.state_dict())\n",
        "\n",
        "    if len(last_100_ep_rewards) == 100:\n",
        "        last_100_ep_rewards.pop(0)\n",
        "    last_100_ep_rewards.append(ep_reward)\n",
        "\n",
        "    training_state.update({'episode':episode,'epsilon':epsilon,'cur_frame':cur_frame,'last_100_ep_rewards':last_100_ep_rewards})\n",
        "\n",
        "    if episode % log_interval == 0:\n",
        "        avg_reward = np.mean(last_100_ep_rewards) if last_100_ep_rewards else ep_reward\n",
        "        logs = training_state['training_logs']\n",
        "        logs['episodes'].append(episode)\n",
        "        logs['rewards'].append(ep_reward)\n",
        "        logs['avg_rewards'].append(avg_reward)\n",
        "        logs['losses'].append(float(loss_val.item()) if isinstance(loss_val, torch.Tensor) else 0.0)\n",
        "        logs['epsilon_values'].append(epsilon)\n",
        "        logs['frames'].append(cur_frame)\n",
        "        print(f\"Ep {episode}/{num_episodes}, ε={epsilon:.3f}, Loss={float(loss_val.item()) if isinstance(loss_val, torch.Tensor) else 0.0:.4f}, AvgR={avg_reward:.2f}\")\n",
        "        print_memory_usage()\n",
        "\n",
        "        with open(logs_dir/\"latest_logs.json\",'w') as f:\n",
        "            json.dump(logs,f,indent=2)\n",
        "\n",
        "    if episode % save_interval == 0:\n",
        "        save_checkpoint(episode, main_nn, target_nn, optimizer, buffer, training_state)\n",
        "\n",
        "    # Memory check\n",
        "    if psutil.virtual_memory().percent > 85:\n",
        "        print(\"WARNING: High memory usage detected. Forcing garbage collection...\")\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Training completed!\")\n",
        "# Final save\n",
        "save_checkpoint(training_state['episode'], main_nn, target_nn, optimizer, buffer, training_state)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "iu_ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
